{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import torch\n",
    "import torch.distributions as dist\n",
    "from scipy.stats import bernoulli\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "bernoulli = dist.Bernoulli(torch.tensor([0.5]))\n",
    "print(bernoulli.sample())\n",
    "# draw 1000 samples\n",
    "\n",
    "samples = [bernoulli.sample((1000,))]\n",
    "# mean of all samples with Bernoulli distribution\n",
    "print(f\"Mean:{torch.mean(samples[0])}\")\n",
    "# standard deviation of all samples with Bernoulli distribution\n",
    "print(f\"Standard Deviation:{torch.std(samples[0])}\")\n",
    "# generate graph for all samples with Bernoulli distribution; show mean and standard deviation\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(samples[0], bins=2)\n",
    "plt.title('Bernoulli Distribution')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.axvline(torch.mean(samples[0]), color='r', linestyle='dashed', linewidth=1)\n",
    "plt.axvline(torch.mean(samples[0]) + torch.std(samples[0]), color='g', linestyle='dashed', linewidth=1)\n",
    "plt.axvline(torch.mean(samples[0]) - torch.std(samples[0]), color='g', linestyle='dashed', linewidth=1)\n",
    "plt.show()\n",
    "\n"
   ],
   "id": "6c9b25475e1d683f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T05:47:58.330647Z",
     "start_time": "2025-02-23T05:47:56.747067Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "a = torch.randn(2,3)\n",
    "\n",
    "print(a)"
   ],
   "id": "1b0892142c5b277a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1991,  0.0149, -0.1082],\n",
      "        [-1.0808,  0.7144,  0.5112]])\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from matplotlib_inline import backend_inline\n",
    "\n",
    "def f(x):\n",
    "    return 3 * x ** 2 - 4 * x\n",
    "\n",
    "for h in 10.0**np.arange(-1, -50, -5):\n",
    "    print(f'h={h:.50f}, numerical limit={(f(1+h)-f(1))/h:.50f}')"
   ],
   "id": "e08e504f8357c807",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T05:50:06.353355Z",
     "start_time": "2025-02-23T05:50:06.075848Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"CUDA available: {torch.mps.is_available()}\")\n",
    "# check if CUDA is available\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "# check if CUDA is available\n",
    "print(f\"CUDA device count: {torch.cuda.device_count()}\")\n",
    "\n",
    "# Check that MPS is available\n",
    "if not torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"MPS not available because the current PyTorch install was not \"\n",
    "              \"built with MPS enabled.\")\n",
    "    else:\n",
    "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "              \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "\n",
    "else:\n",
    "    mps_device = torch.device(\"mps\")\n",
    "\n",
    "    # Create a Tensor directly on the mps device\n",
    "    x = torch.ones(5, device=mps_device)\n",
    "    # Or\n",
    "    x = torch.ones(5, device=\"mps\")\n",
    "\n",
    "    # Any operation happens on the GPU\n",
    "    y = x * 2\n",
    "\n",
    "    # Move your model to mps just like any other device\n",
    "    model = YourFavoriteNet()\n",
    "    model.to(mps_device)\n",
    "\n",
    "    # Now every call runs on the GPU\n",
    "    pred = model(x)"
   ],
   "id": "d6eb1d04385155f8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "CUDA version: None\n",
      "CUDA device count: 0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'YourFavoriteNet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 28\u001B[0m\n\u001B[1;32m     25\u001B[0m y \u001B[38;5;241m=\u001B[39m x \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m2\u001B[39m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;66;03m# Move your model to mps just like any other device\u001B[39;00m\n\u001B[0;32m---> 28\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mYourFavoriteNet\u001B[49m()\n\u001B[1;32m     29\u001B[0m model\u001B[38;5;241m.\u001B[39mto(mps_device)\n\u001B[1;32m     31\u001B[0m \u001B[38;5;66;03m# Now every call runs on the GPU\u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'YourFavoriteNet' is not defined"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
